{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3e109a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d6f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msalvetti/notebooks_2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-10 10:28:40.117585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from kofscraper import keywords_utils, load_utils, run_analysis, nlp_utils\n",
    "from kofscraper.config import *\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56539a9",
   "metadata": {},
   "source": [
    "# Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bd4c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ARGUS_chunk_p183.parquet is corrupted\n"
     ]
    }
   ],
   "source": [
    "lf = load_utils.load_parquets(\"/home/msalvetti/KOFScraper/chunks/run_id=2025-11-21/parsed\").select(\"ID\", \"url\", \"text\")\n",
    "MODEL_ID = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, padding = 'max_length', max_length = 512, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95533641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202228"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf.select(pl.len()).collect(engine=\"streaming\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa13786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "MODEL_ID = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_ID, dtype = \"auto\", device_map = \"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df802489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def get_embeddings(texts, model, tokenizer):\n",
    "    encoded = tokenizer(texts, padding = True, truncation = True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded)\n",
    "    \n",
    "    sentence_embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    return sentence_embeddings\n",
    "\n",
    "embeddings = get_embeddings(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950d3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts, tokenizer):\n",
    "    return tokenizer(texts, padding = True, truncation = True, return_tensors=\"pt\")\n",
    "\n",
    "def embed(tokens, model):\n",
    "    return(model(tokens))\n",
    "\n",
    "# tok = tokenize(texts, tokenizer)\n",
    "# print(tok)\n",
    "# embs = embed(tok, model)\n",
    "# print(embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72e665",
   "metadata": {},
   "source": [
    "# Pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41110aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file = pq.ParquetFile(\"/home/msalvetti/KOFScraper/chunks/run_id=2025-11-21/parsed/ARGUS_chunk_p1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce47ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pq.read_table(\"/home/msalvetti/KOFScraper/chunks/run_id=2025-11-21/parsed/ARGUS_chunk_p1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83869e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[\"text\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c569a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff6d0e",
   "metadata": {},
   "source": [
    "### Re try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63f4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ARGUS_chunk_p183.parquet is corrupted\n"
     ]
    }
   ],
   "source": [
    "lf = load_utils.load_parquets(\"/home/msalvetti/KOFScraper/chunks/run_id=2025-11-21/parsed\").select(\"ID\", \"url\", \"text\")\n",
    "\n",
    "MAX_CHARS = 5120\n",
    "lf = lf.filter(pl.col(\"text\") != \"\").with_columns(\n",
    "    [pl.when(pl.col(\"text\").str.len_chars() > MAX_CHARS)\n",
    "     .then(pl.col(\"text\").str.slice(0, MAX_CHARS))\n",
    "     .otherwise(pl.col(\"text\")).alias(\"text\")]\n",
    ")\n",
    "\n",
    "lf.sink_parquet(pl.PartitionMaxSize(\"output/\", max_size=2000), mkdir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c4204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1.7%, (10 / 587)\n",
      "ETA: 0:08:42.130699\n",
      "Memory usage: 12863.76171875 MB\n",
      "Done file output/000000ce.parquet\n",
      "Done 3.4%, (20 / 587)\n",
      "ETA: 0:08:35.774330\n",
      "Memory usage: 12879.83984375 MB\n",
      "Done file output/000000bd.parquet\n",
      "Done 5.1%, (30 / 587)\n",
      "ETA: 0:08:31.918018\n",
      "Memory usage: 12888.27734375 MB\n",
      "Done file output/00000197.parquet\n",
      "Done 6.8%, (40 / 587)\n",
      "ETA: 0:08:30.293828\n",
      "Memory usage: 12702.25390625 MB\n",
      "Done file output/00000125.parquet\n",
      "Done 8.5%, (50 / 587)\n",
      "ETA: 0:08:28.797209\n",
      "Memory usage: 12703.40234375 MB\n",
      "Done file output/00000051.parquet\n",
      "Done 10.2%, (60 / 587)\n",
      "ETA: 0:08:19.617840\n",
      "Memory usage: 12709.3515625 MB\n",
      "Done file output/0000023c.parquet\n",
      "Done 11.9%, (70 / 587)\n",
      "ETA: 0:08:04.412433\n",
      "Memory usage: 12709.796875 MB\n",
      "Done file output/000000e9.parquet\n",
      "Done 13.6%, (80 / 587)\n",
      "ETA: 0:07:54.991160\n",
      "Memory usage: 12711.4296875 MB\n",
      "Done file output/0000003e.parquet\n",
      "Done 15.3%, (90 / 587)\n",
      "ETA: 0:07:47.521985\n",
      "Memory usage: 12568.37109375 MB\n",
      "Done file output/00000076.parquet\n",
      "Done 17.0%, (100 / 587)\n",
      "ETA: 0:07:38.622500\n",
      "Memory usage: 12568.72265625 MB\n",
      "Done file output/00000031.parquet\n",
      "Done 18.7%, (110 / 587)\n",
      "ETA: 0:07:36.399363\n",
      "Memory usage: 12257.3125 MB\n",
      "Done file output/00000081.parquet\n",
      "Done 20.4%, (120 / 587)\n",
      "ETA: 0:07:29.415373\n",
      "Memory usage: 12263.265625 MB\n",
      "Done file output/00000089.parquet\n",
      "Done 22.1%, (130 / 587)\n",
      "ETA: 0:07:18.714828\n",
      "Memory usage: 12264.90234375 MB\n",
      "Done file output/000000e8.parquet\n",
      "Done 23.9%, (140 / 587)\n",
      "ETA: 0:07:10.640614\n",
      "Memory usage: 12120.3515625 MB\n",
      "Done file output/000001c4.parquet\n",
      "Done 25.6%, (150 / 587)\n",
      "ETA: 0:07:02.587459\n",
      "Memory usage: 12120.3671875 MB\n",
      "Done file output/0000017a.parquet\n",
      "Done 27.3%, (160 / 587)\n",
      "ETA: 0:06:54.548375\n",
      "Memory usage: 12119.7421875 MB\n",
      "Done file output/0000003a.parquet\n",
      "Done 29.0%, (170 / 587)\n",
      "ETA: 0:06:45.569771\n",
      "Memory usage: 12120.83203125 MB\n",
      "Done file output/000001d5.parquet\n",
      "Done 30.7%, (180 / 587)\n",
      "ETA: 0:06:36.131706\n",
      "Memory usage: 12119.96875 MB\n",
      "Done file output/0000013a.parquet\n",
      "Done 32.4%, (190 / 587)\n",
      "ETA: 0:06:25.269494\n",
      "Memory usage: 12120.32421875 MB\n",
      "Done file output/000001e6.parquet\n",
      "Done 34.1%, (200 / 587)\n",
      "ETA: 0:06:16.234408\n",
      "Memory usage: 12121.1328125 MB\n",
      "Done file output/00000090.parquet\n",
      "Done 35.8%, (210 / 587)\n",
      "ETA: 0:06:08.134024\n",
      "Memory usage: 12120.41796875 MB\n",
      "Done file output/00000213.parquet\n",
      "Done 37.5%, (220 / 587)\n",
      "ETA: 0:05:58.151250\n",
      "Memory usage: 12120.66015625 MB\n",
      "Done file output/000000fe.parquet\n",
      "Done 39.2%, (230 / 587)\n",
      "ETA: 0:05:48.318061\n",
      "Memory usage: 12120.765625 MB\n",
      "Done file output/000001d3.parquet\n",
      "Done 40.9%, (240 / 587)\n",
      "ETA: 0:05:39.637014\n",
      "Memory usage: 12128.41796875 MB\n",
      "Done file output/000000a8.parquet\n",
      "Done 42.6%, (250 / 587)\n",
      "ETA: 0:05:29.959963\n",
      "Memory usage: 12126.5625 MB\n",
      "Done file output/00000157.parquet\n",
      "Done 44.3%, (260 / 587)\n",
      "ETA: 0:05:20.007068\n",
      "Memory usage: 12126.77734375 MB\n",
      "Done file output/0000015f.parquet\n",
      "Done 46.0%, (270 / 587)\n",
      "ETA: 0:05:09.452403\n",
      "Memory usage: 12127.5546875 MB\n",
      "Done file output/000000b2.parquet\n",
      "Done 47.7%, (280 / 587)\n",
      "ETA: 0:05:00.034593\n",
      "Memory usage: 12129.21484375 MB\n",
      "Done file output/00000028.parquet\n",
      "Done 49.4%, (290 / 587)\n",
      "ETA: 0:04:49.960498\n",
      "Memory usage: 12128.44921875 MB\n",
      "Done file output/00000151.parquet\n",
      "Done 51.1%, (300 / 587)\n",
      "ETA: 0:04:39.672581\n",
      "Memory usage: 12129.07421875 MB\n",
      "Done file output/00000170.parquet\n",
      "Done 52.8%, (310 / 587)\n",
      "ETA: 0:04:30.476779\n",
      "Memory usage: 12129.21484375 MB\n",
      "Done file output/000001cc.parquet\n",
      "Done 54.5%, (320 / 587)\n",
      "ETA: 0:04:20.370928\n",
      "Memory usage: 12128.36328125 MB\n",
      "Done file output/00000056.parquet\n",
      "Done 56.2%, (330 / 587)\n",
      "ETA: 0:04:11.236362\n",
      "Memory usage: 12130.53515625 MB\n",
      "Done file output/00000009.parquet\n",
      "Done 57.9%, (340 / 587)\n",
      "ETA: 0:04:01.666192\n",
      "Memory usage: 12131.34765625 MB\n",
      "Done file output/0000003f.parquet\n",
      "Done 59.6%, (350 / 587)\n",
      "ETA: 0:03:52.047507\n",
      "Memory usage: 12131.41015625 MB\n",
      "Done file output/0000007e.parquet\n",
      "Done 61.3%, (360 / 587)\n",
      "ETA: 0:03:42.332212\n",
      "Memory usage: 12131.13671875 MB\n",
      "Done file output/00000065.parquet\n",
      "Done 63.0%, (370 / 587)\n",
      "ETA: 0:03:32.479421\n",
      "Memory usage: 12131.92578125 MB\n",
      "Done file output/000000c7.parquet\n",
      "Done 64.7%, (380 / 587)\n",
      "ETA: 0:03:22.819173\n",
      "Memory usage: 12131.59375 MB\n",
      "Done file output/000000d8.parquet\n",
      "Done 66.4%, (390 / 587)\n",
      "ETA: 0:03:13.437265\n",
      "Memory usage: 12132.25 MB\n",
      "Done file output/000001c6.parquet\n",
      "Done 68.1%, (400 / 587)\n",
      "ETA: 0:03:03.523681\n",
      "Memory usage: 12131.1484375 MB\n",
      "Done file output/0000005f.parquet\n",
      "Done 69.8%, (410 / 587)\n",
      "ETA: 0:02:54.592138\n",
      "Memory usage: 11989.3125 MB\n",
      "Done file output/000001ce.parquet\n",
      "Done 71.6%, (420 / 587)\n",
      "ETA: 0:02:45.366917\n",
      "Memory usage: 11989.9140625 MB\n",
      "Done file output/00000057.parquet\n",
      "Done 73.3%, (430 / 587)\n",
      "ETA: 0:02:35.503000\n",
      "Memory usage: 11772.57421875 MB\n",
      "Done file output/0000010d.parquet\n",
      "Done 75.0%, (440 / 587)\n",
      "ETA: 0:02:26.402249\n",
      "Memory usage: 11310.46484375 MB\n",
      "Done file output/000001dc.parquet\n",
      "Done 76.7%, (450 / 587)\n",
      "ETA: 0:02:18.124567\n",
      "Memory usage: 10601.62890625 MB\n",
      "Done file output/000001bf.parquet\n",
      "Done 78.4%, (460 / 587)\n",
      "ETA: 0:02:08.413541\n",
      "Memory usage: 10394.90234375 MB\n",
      "Done file output/0000021f.parquet\n",
      "Done 80.1%, (470 / 587)\n",
      "ETA: 0:01:58.229822\n",
      "Memory usage: 10396.98046875 MB\n",
      "Done file output/00000083.parquet\n",
      "Done 81.8%, (480 / 587)\n",
      "ETA: 0:01:48.062077\n",
      "Memory usage: 10405.39453125 MB\n",
      "Done file output/0000021b.parquet\n",
      "Done 83.5%, (490 / 587)\n",
      "ETA: 0:01:37.791570\n",
      "Memory usage: 10405.12109375 MB\n",
      "Done file output/00000111.parquet\n",
      "Done 85.2%, (500 / 587)\n",
      "ETA: 0:01:27.481798\n",
      "Memory usage: 10404.5390625 MB\n",
      "Done file output/0000003d.parquet\n",
      "Done 86.9%, (510 / 587)\n",
      "ETA: 0:01:17.469637\n",
      "Memory usage: 10405.359375 MB\n",
      "Done file output/000001ca.parquet\n",
      "Done 88.6%, (520 / 587)\n",
      "ETA: 0:01:07.370698\n",
      "Memory usage: 10406.83203125 MB\n",
      "Done file output/00000143.parquet\n",
      "Done 90.3%, (530 / 587)\n",
      "ETA: 0:00:57.317804\n",
      "Memory usage: 10406.57421875 MB\n",
      "Done file output/00000124.parquet\n",
      "Done 92.0%, (540 / 587)\n",
      "ETA: 0:00:47.296969\n",
      "Memory usage: 10407.42578125 MB\n",
      "Done file output/000001f2.parquet\n",
      "Done 93.7%, (550 / 587)\n",
      "ETA: 0:00:37.303318\n",
      "Memory usage: 10416.12890625 MB\n",
      "Done file output/000001ba.parquet\n",
      "Done 95.4%, (560 / 587)\n",
      "ETA: 0:00:27.236331\n",
      "Memory usage: 10132.1015625 MB\n",
      "Done file output/000001ac.parquet\n",
      "Done 97.1%, (570 / 587)\n",
      "ETA: 0:00:17.131634\n",
      "Memory usage: 10135.91015625 MB\n",
      "Done file output/00000029.parquet\n",
      "Done 98.8%, (580 / 587)\n",
      "ETA: 0:00:07.050520\n",
      "Memory usage: 10138.25390625 MB\n",
      "Done file output/00000014.parquet\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import psutil\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "MODEL_ID = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer(t, padding = 'max_length', max_length = 512, truncation = True, return_tensors = \"pt\").data\n",
    "    \n",
    "\n",
    "mem: List[str] = []\n",
    "\n",
    "i = 0\n",
    "out_path = Path(\"out\")\n",
    "out_path.mkdir(exist_ok=True)\n",
    "n_files = len(glob.glob(\"output/000*.parquet\"))\n",
    "start = time.time()\n",
    "\n",
    "with open(\"memory_usage.txt\", \"w+\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "for path in glob.glob(\"output/000*.parquet\"):\n",
    "    i += 1\n",
    "    df = pl.read_parquet(path).unique(\"text\")\n",
    "    texts = df[\"text\"].to_list()\n",
    "    toks = tokenize(texts)\n",
    "\n",
    "    table = pa.Table.from_pydict(toks)\n",
    "    out_name = out_path / f\"tokens_{i:09d}.parquet\"\n",
    "    pq.write_table(table, out_name)\n",
    "    end = time.time()\n",
    "    eta = timedelta(seconds = (((end - start) / (i/n_files)) - (end - start)))\n",
    "    process = psutil.Process()\n",
    "    mem.append(process.memory_info().rss / 1024 / 1024)\n",
    "\n",
    "    if (i%10 == 0):\n",
    "        print(f\"Done {(i*100/n_files):.1f}%, ({i} / {n_files})\")\n",
    "        print(f\"ETA: {eta}\")\n",
    "        print(f\"Memory usage: {process.memory_info().rss / 1024 / 1024} MB\")\n",
    "        print(f'Done file {path}')\n",
    "    \n",
    "    if (i%100 == 0): \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, padding = 'max_length', max_length = 512, truncation = True, use_fast = True)\n",
    "        with open(\"memory_usage.txt\", \"a\") as f:\n",
    "            f.write(\",\".join(str(m) for m in mem))\n",
    "            mem = []\n",
    "\n",
    "    del table, texts, toks\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc588f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"memory_usage.txt\") as f:\n",
    "    mem = f.read()\n",
    "mem = mem.split(\",\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"./style.mplstyle\")\n",
    "plot = pd.DataFrame({\"mem\": mem})\n",
    "\n",
    "plot[\"time\"] = plot.index\n",
    "plot[\"time\"] = pd.to_numeric(plot[\"time\"], errors=\"coerce\")\n",
    "plot[\"mem\"]  = pd.to_numeric(plot[\"mem\"], errors=\"coerce\")\n",
    "plot[\"mem\"] = plot[\"mem\"] / 1024\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = plt.subplot()\n",
    "plt.plot(\"time\", \"mem\", data = plot)\n",
    "ax.set_xlim(0)\n",
    "ax.set_ylim(0,30.5)\n",
    "ax.set_xticks([])\n",
    "# ax.xaxis.set_major_locator(MultipleLocator(100))\n",
    "# ax.xaxis.set_minor_locator(MultipleLocator(50))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(2))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.plot(1, 0, \">k\", transform=ax.get_yaxis_transform(), clip_on = False)\n",
    "ax.fill_between(x = \"time\", y1=\"mem\", y2=0, data = plot, alpha = 0.2)\n",
    "plt.ylabel(\"Memory in GBs\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9528fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "lf = pl.scan_parquet(\"out/tokens*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a7a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = lf.select('input_ids').collect(engine = \"streaming\")[\"input_ids\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a94ed3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.get_input_embeddings()\n",
    "\n",
    "def get_tokens(lf, chunk_size):\n",
    "    n_rows = lf.select(pl.len()).collect(engine = \"streaming\").item()\n",
    "    for i in range(0, n_rows, chunk_size):\n",
    "        tokens = lf.slice(i, chunk_size).select(\"input_ids\").collect(engine = \"streaming\")[\"input_ids\"].to_list()\n",
    "        embs = embed(torch.tensor(tokens, dtype = torch.long))\n",
    "        frame = pl.DataFrame({'embedding': embs})\n",
    "        frame.write_parquet(f\"embedding_{i}.parequt\")\n",
    "\n",
    "        del tokens, embs, frame\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455721b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "f = pq.read_table(\"output/00000000.parquet\")\n",
    "texts = f.to_pydict()[\"text\"]\n",
    "\n",
    "MODEL_ID = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer(t, padding = 'max_length', max_length = 512, truncation = True, return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e1e6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = tokenize(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47380e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaaa8f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model = AutoModel.from_pretrained(MODEL_ID)\n\u001b[32m      5\u001b[39m embed = model.get_input_embeddings()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m toks_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m embs = embed(toks_tensor)\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0787192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"out/tokens_000000001.parquet\")[\"input_ids\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38d608c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m enc = tokenizer(texts,return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation = \u001b[38;5;28;01mTrue\u001b[39;00m, padding = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43menc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:466\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    463\u001b[39m \u001b[33;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m sa_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    475\u001b[39m     sa_output, sa_weights = sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:392\u001b[39m, in \u001b[36mDistilBertSdpaAttention.forward\u001b[39m\u001b[34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    389\u001b[39m k = shape(\u001b[38;5;28mself\u001b[39m.k_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[32m    390\u001b[39m v = shape(\u001b[38;5;28mself\u001b[39m.v_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m attn_output = unshape(attn_output)\n\u001b[32m    402\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.out_lin(attn_output)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "f = pq.read_table(\"output/00000000.parquet\")\n",
    "texts = f.to_pydict()[\"text\"]\n",
    "\n",
    "enc = tokenizer(texts,return_tensors=\"pt\", truncation = True, padding = True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(**enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79400b4b",
   "metadata": {},
   "source": [
    "# Make some order\n",
    "\n",
    "Basically I want the whole output of the tokenizer, then pass it to model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa498b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "f = pq.read_table(\"output/00000000.parquet\")\n",
    "texts = f.to_pydict()[\"text\"][0:10]\n",
    "\n",
    "MODEL_ID = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "def tokenize(t):\n",
    "    return tokenizer(t, padding = 'max_length', max_length = 512, truncation = True, return_tensors = \"pt\")\n",
    "\n",
    "toks = tokenize(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9eb8a",
   "metadata": {},
   "source": [
    "At this point we have tokens, now we need embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d2623f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m toks = transformers.tokenization_utils_base.BatchEncoding({\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: input_ids, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m: attention_mask})\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtoks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m sentence_embeddings = output.last_hidden_state[:, \u001b[32m0\u001b[39m, :].numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:484\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    481\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    485\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    487\u001b[39m output = (ffn_output,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:418\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:423\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    421\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    422\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks_2/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_ID)\n",
    "input_ids = torch.tensor(pl.read_parquet(\"out/tokens_000000001.parquet\").to_dict()[\"input_ids\"])\n",
    "attention_mask = torch.tensor(pl.read_parquet(\"out/tokens_000000001.parquet\").to_dict()[\"attention_mask\"])\n",
    "toks = transformers.tokenization_utils_base.BatchEncoding({\"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**toks)\n",
    "\n",
    "sentence_embeddings = output.last_hidden_state[:, 0, :].numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5b54f",
   "metadata": {},
   "source": [
    "Ok this works. Now we only want to write the tokens to a file and be able to retrieve them as a transformers.tokenization_utils_base.BatchEncoding type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "664fd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pl.read_parquet(\"out/tokens_000000001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e9a24b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(pl.read_parquet(\"out/tokens_000000001.parquet\").to_dict()[\"input_ids\"])\n",
    "torch.tensor(pl.read_parquet(\"out/tokens_000000001.parquet\").to_dict()[\"attention_mask\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
